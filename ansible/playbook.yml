---
- name: Setup Docker Swarm Infrastructure
  hosts: all
  become: true
  vars:
    data_disk_device: /dev/vdb
    data_mount_point: /mnt/docker-data
  
  tasks:
    - name: Check if data disk exists
      stat:
        path: "{{ data_disk_device }}"
      register: data_disk

    - name: Format data disk with ext4
      filesystem:
        fstype: ext4
        resizefs: true
        dev: "{{ data_disk_device }}"
      when: data_disk.stat.exists

    # Usamos um diretório de volumes diferente do padrão do Docker para evitar restrições de permissões (exemplo: nodeexporter)
    - name: Mount data disk to Docker data root directory
      mount:
        path: "{{ data_mount_point }}"
        src: "{{ data_disk_device }}"
        fstype: ext4
        opts: defaults
        state: mounted
      when: data_disk.stat.exists

    # FIX enquanto houver problema GRUB
    - name: Detect the root disk device
      shell: |
        lsblk -J -o NAME,MOUNTPOINT | jq -r '
          .blockdevices[] |
          select(.children[]?.mountpoint == "/") |
          "/dev/" + .name'
      register: root_disk_result
      changed_when: false

    - name: Configure GRUB to install to main disk automatically
      debconf:
        name: grub-pc
        question: grub-pc/install_devices
        value: "{{ root_disk_result.stdout }}"
        vtype: multiselect

    - name: Set timezone to UTC
      community.general.timezone:
        name: Etc/UTC

    - name: Set vm.max_map_count for Elasticsearch compatibility
      sysctl:
        name: vm.max_map_count
        value: '262144'
        state: present
        reload: true

    - name: Update and upgrade packages
      apt:
        update_cache: true
        upgrade: yes
      environment:
        DEBIAN_FRONTEND: noninteractive

    - name: Install required packages
      apt:
        name:
          - unattended-upgrades
          - ca-certificates
          - curl
          - gnupg
          - python3-pip
          - nfs-common
        update_cache: true

    - name: Enable unattended upgrades
      copy:
        content: |
          APT::Periodic::Update-Package-Lists "1";
          APT::Periodic::Unattended-Upgrade "1";
        dest: /etc/apt/apt.conf.d/20auto-upgrades

    - name: Configure automatic reboots for unattended-upgrades
      copy:
        dest: /etc/apt/apt.conf.d/52-automatic-reboots
        content: |
          Unattended-Upgrade::Automatic-Reboot "true";
          Unattended-Upgrade::Automatic-Reboot-Time "{{ automatic_reboot_time_utc }}";
      when: automatic_reboot | bool

    - name: Add Docker GPG key
      apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg

    - name: Add Docker repository
      apt_repository:
        repo: "deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable"

    - name: Install Docker
      apt:
        name:
          - docker-ce
          - docker-ce-cli
          - containerd.io

    - name: Create Docker service override directory
      file:
        path: /etc/systemd/system/docker.service.d
        state: directory
        mode: '0755'

    - name: Configure Docker daemon resource limits
      copy:
        content: |
          [Service]
          MemoryHigh=60%
          MemoryMax=80%
          MemoryAccounting=yes
        dest: /etc/systemd/system/docker.service.d/limits.conf
        mode: '0644'
      notify: restart docker

    - name: Configure Docker daemon log rotation, metrics and data root
      copy:
        dest: /etc/docker/daemon.json
        content: |
          {
            "log-driver": "json-file",
            "log-opts": {
              "max-size": "10m",
              "max-file": "3"
            },
            "metrics-addr": "0.0.0.0:9323",
            "data-root": "{{ data_mount_point }}"
          }
        mode: '0644'
      notify: restart docker

    - name: Start and enable Docker service
      systemd:
        name: docker
        state: started
        enabled: true
        daemon_reload: true

    - name: Install Docker Python module
      apt:
        name: python3-docker
        update_cache: true

    - name: Calculate available memory for each host
      set_fact:
        available_memory_mb: "{{ ((ansible_memtotal_mb * 0.9) | int) - 300 }}"

  handlers:
    - name: restart docker
      systemd:
        name: docker
        state: restarted
        daemon_reload: true

- name: Initialize Docker Swarm
  hosts: managers[0]
  become: true
  tasks:
    - name: Initialize Docker Swarm
      community.docker.docker_swarm:
        state: present
        advertise_addr: "{{ private_ip }}"

    - name: Get swarm join tokens
      community.docker.docker_swarm_info:
      register: swarm_info

    - name: Store join tokens
      set_fact:
        manager_token: "{{ swarm_info.swarm_facts.JoinTokens.Manager }}"
        worker_token: "{{ swarm_info.swarm_facts.JoinTokens.Worker }}"

- name: Join managers to swarm
  hosts: managers[1:]
  become: true
  tasks:
    - name: Join as manager
      community.docker.docker_swarm:
        state: join
        advertise_addr: "{{ private_ip }}"
        join_token: "{{ hostvars[groups['managers'][0]]['manager_token'] }}"
        remote_addrs:
          - "{{ hostvars[groups['managers'][0]]['private_ip'] }}:2377"

- name: Join workers to swarm
  hosts: workers
  become: true
  tasks:
    - name: Join as worker
      community.docker.docker_swarm:
        state: join
        advertise_addr: "{{ private_ip }}"
        join_token: "{{ hostvars[groups['managers'][0]]['worker_token'] }}"
        remote_addrs:
          - "{{ hostvars[groups['managers'][0]]['private_ip'] }}:2377"

- name: Apply node labels
  hosts: workers
  become: true
  tasks:
    - name: Apply labels to this worker node
      community.docker.docker_node:
        hostname: "{{ inventory_hostname }}"
        labels: "{{ labels }}"
        labels_state: replace
      delegate_to: "{{ groups['managers'][0] }}"
      when: labels is defined and labels | length > 0

- name: Setup NFS Server on manager-1
  hosts: managers[0]
  become: true
  tasks:
    - name: Install NFS server
      apt:
        name: nfs-kernel-server
        state: present
        update_cache: true

    - name: Create NFS export directory
      file:
        path: /opt/nfs-stacks
        state: directory
        owner: root
        group: root
        mode: '0755'

    - name: Configure NFS exports for managers (read-write)
      lineinfile:
        path: /etc/exports
        line: "/opt/nfs-stacks {{ item }}(rw,sync,no_subtree_check,no_root_squash)"
        create: true
      loop: "{{ groups['managers'] | map('extract', hostvars, 'private_ip') | list }}"
      notify: restart nfs server

    - name: Configure NFS exports for workers (read-only)
      lineinfile:
        path: /etc/exports
        line: "/opt/nfs-stacks {{ item }}(ro,sync,no_subtree_check,no_root_squash)"
        create: true
      loop: "{{ groups['workers'] | map('extract', hostvars, 'private_ip') | list }}"
      notify: restart nfs server

    - name: Start and enable NFS server
      systemd:
        name: nfs-kernel-server
        state: started
        enabled: true

  handlers:
    - name: restart nfs server
      systemd:
        name: nfs-kernel-server
        state: restarted

- name: Mount NFS shares on all nodes
  hosts: all
  become: true
  tasks:
    - name: Determine NFS mount options based on node type
      set_fact:
        nfs_options: "{{ 'rw,sync' if inventory_hostname in groups['managers'] else 'ro,sync' }}"

    - name: Mount NFS share
      mount:
        path: /opt/stacks
        src: "{{ hostvars[groups['managers'][0]]['private_ip'] }}:/opt/nfs-stacks"
        fstype: nfs
        opts: "{{ nfs_options }},hard,intr"
        state: mounted

- name: Deploy Docker Stacks
  hosts: managers[0]
  become: true
  vars:
    stacks_dir: "{{ playbook_dir }}/../../environments/dev/stacks"
    secrets_file: "{{ playbook_dir }}/../../environments/dev/secrets.yaml"
  tasks:
    - name: Install python3-jsondiff for stack management
      apt:
        name: python3-jsondiff
        state: present
        update_cache: true

    - name: Logout from registry if password env var is empty
      community.docker.docker_login:
        registry_url: "{{ lookup('env', 'DOCKER_REGISTRY_URL') | default('https://index.docker.io/v1/', true) }}"
        state: absent
      when:
        - (lookup('env', 'DOCKER_REGISTRY_PASSWORD') | default('', true)) == ''

    - name: Login to container registry from environment variables (optional)
      community.docker.docker_login:
        registry_url: "{{ lookup('env', 'DOCKER_REGISTRY_URL') | default('https://index.docker.io/v1/', true) }}"
        username: "{{ lookup('env', 'DOCKER_REGISTRY_USERNAME') | default('nobody', true) }}"
        password: "{{ lookup('env', 'DOCKER_REGISTRY_PASSWORD') | default('', true) }}"
        reauthorize: true
        state: present
      when:
        - (lookup('env', 'DOCKER_REGISTRY_PASSWORD') | default('', true)) != ''

    - name: Check permissions of secrets file
      stat:
        path: "{{ secrets_file }}"
      register: secrets_file_stat
      delegate_to: localhost
      become: false

    - name: Fail if secrets file is missing or has wrong permissions
      fail:
        msg: "Secrets file '{{ secrets_file }}' must exist and have permissions set to 600. Please create it or run 'chmod 600 {{ secrets_file }}' to fix."
      when: not secrets_file_stat.stat.exists or secrets_file_stat.stat.mode != '0600'

    - name: Find docker-compose files in local stacks directory
      find:
        paths: "{{ stacks_dir }}"
        patterns: "docker-compose.yaml,docker-compose.yml"
        recurse: true
      register: compose_files_local
      delegate_to: localhost
      become: false

    - name: Read and combine all secrets from compose files
      vars:
        compose_content: "{{ lookup('file', item.path) | from_yaml }}"
      set_fact:
        all_secrets: "{{ all_secrets | default([]) + (compose_content.secrets | default({})).keys() | list }}"
      loop: "{{ compose_files_local.files }}"
      delegate_to: localhost
      become: false

    - name: Load secret values from secrets file
      include_vars:
        file: "{{ secrets_file }}"
        name: secret_values

    - name: Create Docker secrets from compose files
      community.docker.docker_secret:
        name: "{{ item }}"
        data: "{{ secret_values[item] }}"
        state: present
      loop: "{{ all_secrets | unique }}"
      when: all_secrets is defined

    - name: Find stack subdirectories on Ansible controller
      find:
        paths: "{{ stacks_dir }}"
        file_type: directory
        depth: 1
      register: stack_subdirs
      delegate_to: localhost
      become: false

    - name: Sync each stack directory individually to NFS mount
      synchronize:
        src: "{{ item.path }}/"
        dest: "/opt/stacks/{{ item.path | basename }}/"
        delete: true
        archive: false # don't copy owner and perms from localhost
        recursive: true # needed because we turned off archive
        times: true # preserve times across task runs to avoid unneeded updates
      delegate_to: localhost
      become: false
      register: sync_results
      loop: "{{ stack_subdirs.files }}"
      loop_control:
        label: "{{ item.path | basename }}"

    - name: Create list of changed stacks
      set_fact:
        changed_stacks: >-
          {{
            sync_results.results
            | selectattr('changed', 'equalto', true)
            | map(attribute='item.path')
            | map('basename')
            | map('regex_replace', '^[0-9]+-', '')
            | list
          }}

    - name: Get services for each changed stack
      shell: docker service ls --filter label=com.docker.stack.namespace={{ item }} --format json | jq -r '.Name'
      register: stack_services
      loop: "{{ changed_stacks }}"
      when: changed_stacks | length > 0

    - name: Find docker-compose files in NFS mount
      find:
        paths: /opt/stacks
        patterns: "docker-compose.yaml,docker-compose.yml"
        recurse: true
      register: compose_files

    # As stacks são implantadas em ordem alfabética, conforme o nome do diretório.
    # Para controlar a ordem, prefixe os diretórios com "NN-".
    # O prefixo é removido do nome da stack para evitar que ela seja recriada caso ele mude.
    - name: Deploy each stack from NFS mount
      community.docker.docker_stack:
        name: "{{ (item.path | dirname | basename) | regex_replace('^[0-9]+-', '') }}"
        prune: true
        with_registry_auth: true
        compose:
          - "{{ item.path }}"
        state: present
      environment:
        DOMAIN_SUFFIX: "{{ domain_suffix }}"
      with_items: "{{ compose_files.files | sort(attribute='path') }}"
      when: compose_files.files | length > 0

    # Forçamos update de serviços quando mudam arquivos diferente do compose na árvore da stack, o que não é detectado pelo passo acima.
    - name: Force update services in changed stacks
      command: docker service update --force {{ item }}
      loop: "{{ stack_services.results | map(attribute='stdout_lines') | flatten }}"
      when: 
        - stack_services.results is defined
